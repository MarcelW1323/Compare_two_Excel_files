{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook compares two excel files and outputs a third excel file with the differences.\n",
    "\n",
    "Restrictions:\n",
    "* Each of the two excel file has only one excel sheet (tab). \n",
    "* The two excel files need to have the same column headers and the same number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import pandas as pd          # For the ease of reading and writing excel files and data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters / Constants\n",
    "## File names\n",
    "df1_file        = \"File1.xlsx\"                         # Name of the first file to compare\n",
    "df2_file        = \"File2.xlsx\"                         # Name of the second file to compare\n",
    "output_file     = \"Outputfile.xlsx\"                    # Name of the output file for the result of the comparisation\n",
    "\n",
    "## Key fields used in comparing the excel files (to give a row an unique index)\n",
    "# Use a list of column headers to identify a row uniquely\n",
    "indexfields     = [\"Keyfield1\", \"Keyfield2\", \"Keyfield3\"]\n",
    "\n",
    "## Miscellaneous\n",
    "NoValue         = \"NoValue\"                            # Which string value to use for NaN-values (Not-a-Number)\n",
    "skip_rows       = 0                                    # Number of rows to skip in both excel files\n",
    "dtype_object    = True                                 # True if indexfields should be treated as objects, False otherwise\n",
    "unnamed_remove  = True                                 # True if unnamed columns need to be removed, False otherwise\n",
    "\n",
    "## Status\n",
    "status_column   = \"status\"                             # Name of the additional column for the status of each row\n",
    "status_deleted  = \"Deleted  (Present in 1, not in 2)\"  # The row is present in dataframe 1, not in dataframe 2\n",
    "status_new      = \"New      (Not in 1, present in 2)\"  # The row is not present in dataframe 1, but present in dataframe 2\n",
    "status_same     = \"Same     (1 == 2)\"                  # The row is equal in dataframe 1 and dataframe 2\n",
    "status_modified = \"Modified (1 <> 2)\"                  # The row is not equal in dataframe 1 and dataframe 2\n",
    "\n",
    "## Dataframe\n",
    "dataframe_id    = \"Dataframe-ID\"                       # Name of the additional column for the dataframe identifier\n",
    "dataframe_1     = \"df1\"                                # Name of the dataframe identifier for dataframe 1\n",
    "dataframe_2     = \"df2\"                                # Name of the dataframe identifier for dataframe 1\n",
    "df1todf2marker  = \" ---> \"                             # Recognizable text to be used between 2 different values of the same cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up depends on value of dtype_object\n",
    "if dtype_object:\n",
    "    # dtype_object is True\n",
    "    dtype_info = dict.fromkeys(indexfields, object)\n",
    "    # With this dictionary, all indexfields will be treated as Pandas Objects (no decimal representation of numeric key values)\n",
    "else:\n",
    "    # dtype_object is not True\n",
    "    dtype_info = None\n",
    "# Print the output of this step\n",
    "print(dtype_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the excel files and place them in the data frames\n",
    "df1 = pd.read_excel(df1_file, skiprows=skip_rows, dtype=dtype_info).fillna(NoValue)\n",
    "print(\"File\", df1_file, \"has\", df1.shape[0], \"rows and\", df1.shape[1], \"columns\")\n",
    "df2 = pd.read_excel(df2_file, skiprows=skip_rows, dtype=dtype_info).fillna(NoValue)\n",
    "print(\"File\", df2_file, \"has\", df2.shape[0], \"rows and\", df2.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the dataframe-ID to each dataframe\n",
    "df1[dataframe_id] = dataframe_1\n",
    "df2[dataframe_id] = dataframe_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 lines of dataframe 1 and show the columns of dataframe 1\n",
    "display(df1.head())\n",
    "display(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all \"Unnamed: \"-columns\n",
    "if unnamed_remove:\n",
    "    # Unnamed columns need to be removed\n",
    "    columntitle = list(df1.columns)\n",
    "    print(\"Old titles:\", len(columntitle), \"\\n\", columntitle)\n",
    "    title_new = [item for item in columntitle if \"Unnamed: \" not in item]\n",
    "    print(\"\\nNew titles:\", len(title_new), \"\\n\", title_new)\n",
    "\n",
    "    print(\"\\nOld shapes:\", df1.shape, df2.shape)\n",
    "    df1 = df1[title_new].copy()\n",
    "    df2 = df2[title_new].copy()\n",
    "    print(\"New shapes:\", df1.shape, df2.shape)\n",
    "else:\n",
    "    # Unnamed columns will not be removed\n",
    "    print(\"No attempt in removing unnamed columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index\n",
    "df1 = df1.set_index(indexfields)\n",
    "display(df1.head())\n",
    "\n",
    "df2 = df2.set_index(indexfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both dataframes\n",
    "df3 = pd.concat([df1,df2],sort=False)\n",
    "display(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the shapes of the three dataframes\n",
    "print(\"Shape of individual dataframes :\", df1.shape, \"and\", df2.shape)\n",
    "print(\"Shape of concatenated dataframe:\", df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign status to rows who only occur once\n",
    "df3.loc[~df3.index.isin(df2.index), status_column] = status_deleted     # if not in df2 index then deleted\n",
    "df3.loc[~df3.index.isin(df1.index), status_column] = status_new         # if not in df1 index then new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there rows who occor more than once?\n",
    "df3.loc[~df3[status_column].isin([status_deleted, status_new])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect rows of df2 who are also in df1\n",
    "df2indf1 = df3.loc[(~df3[status_column].isin([status_deleted, status_new])) & (df3[dataframe_id] == dataframe_2)].copy()\n",
    "print(\"df2indf1  :\", df2indf1.shape)\n",
    "# Remove rows in df3 who occur in df1 as well as df2, but who originate from df2:\n",
    "# We want to keep only those rows who already have a assigned status or who originate from df1\n",
    "print(\"df3 before:\", df3.shape)\n",
    "df3 = df3.loc[(df3[status_column].isin([status_deleted, status_new])) | (df3[dataframe_id] == dataframe_1)].copy()\n",
    "print(\"df3 after :\", df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows\n",
    "display(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionality below this cell require that both dataframes have unique rows base on the index\n",
    "assert len(df1.index.unique()) == df1.shape[0], \"Index is not unique in df1\"\n",
    "assert len(df2.index.unique()) == df2.shape[0], \"Index is not unique in df2\"\n",
    "# Now we have controlled that both dataframes have unique rows based on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of the dataframe based on the index\n",
    "dict_df2 = df2.to_dict(\"index\")\n",
    "print(\"Dictionary has\", len(dict_df2),\"entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_row(row):\n",
    "    # Follow-up depends on type of the field status_column\n",
    "    if type(row[status_column]) == type(status_deleted):\n",
    "        # Type of field status_column matches the type of an already assigned value, this record can be skipped.\n",
    "        return row\n",
    "    \n",
    "    # Now the rows that didn't have an assigned value will be treated\n",
    "    indexlist = list(row.index)       # list of field names of the row\n",
    "    indexlist.remove(status_column)   # Remove the field name of the added status_column\n",
    "    indexlist.remove(dataframe_id)    # Remove the field name of the added dataframe-identifier\n",
    "    row2_dict = dict_df2[row.name]    # Get the row to compare from the dictionary (from dataframe 2)\n",
    "    \n",
    "    row[status_column] = status_same  # Assume that the rows are identical\n",
    "    for element in indexlist:\n",
    "        # Do the following for each field name \n",
    "        # Follow-up depends on the content of the same field in both rows\n",
    "        if row[element] != row2_dict[element]:\n",
    "            # Inhoud van het veld in beide rijen is niet gelijk\n",
    "            row[status_column] = status_modified                                           # Markeer the row as change\n",
    "            row[element] = str(row[element]) + df1todf2marker + str(row2_dict[element])    # Record the change\n",
    "            print(row.name, element, row[element])                                         # Show the difference\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function above for each row\n",
    "df4 = df3.apply(func=compare_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the output file\n",
    "df4.to_excel(output_file, merge_cells=False)\n",
    "print(\"Output written to\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
